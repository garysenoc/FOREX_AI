{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m absolute_import\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m division\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m print_function\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mtf\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "\n",
      "sys.path.append(\u001b[33m'\u001b[39;49;00m\u001b[33menvironment\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36menv\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m ForexEnv\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtf_agents\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36menvironments\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m utils\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtf_agents\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36menvironments\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m tf_py_environment\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtf_agents\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36magents\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdqn\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m dqn_agent\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtf_agents\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnetworks\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m q_network\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtf_agents\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m common\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mlearn\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m learningHelper\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mmatplotlib\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mpyplot\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mplt\u001b[39;49;00m\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtrain\u001b[39;49;00m(model,epoch):\n",
      "    model.train_agent(epoch)\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmain\u001b[39;49;00m():\n",
      "\n",
      "\n",
      "    tf.random.set_seed(\u001b[34m12\u001b[39;49;00m)\n",
      "    tf.print(tf.config.list_physical_devices(\u001b[33m'\u001b[39;49;00m\u001b[33mGPU\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) )\n",
      "    tf.compat.v1.enable_v2_behavior()\n",
      "\n",
      "    environment = ForexEnv(is_evaluation=\u001b[34mTrue\u001b[39;49;00m)\n",
      "    utils.validate_py_environment(environment, episodes=\u001b[34m3\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33maction_spec:\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, environment.action_spec())\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mtime_step_spec.observation:\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, environment.time_step_spec().observation)\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mtime_step_spec.step_type:\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, environment.time_step_spec().step_type)\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mtime_step_spec.discount:\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, environment.time_step_spec().discount)\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mtime_step_spec.reward:\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, environment.time_step_spec().reward)\n",
      "\n",
      "    train_env = tf_py_environment.TFPyEnvironment(ForexEnv())\n",
      "    eval_env = tf_py_environment.TFPyEnvironment(ForexEnv(is_evaluation=\u001b[34mTrue\u001b[39;49;00m))\n",
      "\n",
      "    start = \u001b[34m1000\u001b[39;49;00m\n",
      "    goal = \u001b[34m1050\u001b[39;49;00m\n",
      "\n",
      "    \u001b[37m# fig, ax = plt.subplots()\u001b[39;49;00m\n",
      "    \u001b[37m# plt.axhline(y = start,color=\"brown\",label=\"Start\")\u001b[39;49;00m\n",
      "    \u001b[37m# plt.axhline(y = goal,color=\"blue\",label=\"Goal\")\u001b[39;49;00m\n",
      "    \u001b[37m# ax.plot(environment.reward_list, color = 'green', label = 'Rewards')\u001b[39;49;00m\n",
      "    \u001b[37m# ax.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\u001b[39;49;00m\n",
      "    \u001b[37m# # plt.show()\u001b[39;49;00m\n",
      "\n",
      "    learning_rate = \u001b[34m1e-3\u001b[39;49;00m  \n",
      "\n",
      "    \u001b[37m#network configuration\u001b[39;49;00m\n",
      "    fc_layer_params = (\u001b[34m40\u001b[39;49;00m,)\n",
      "\n",
      "    \u001b[37m# as we are using dictionary in our enviroment, we will create preprocessing layer\u001b[39;49;00m\n",
      "    preprocessing_layers = {\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: tf.keras.layers.Flatten(),\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mpos\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: tf.keras.layers.Dense(\u001b[34m2\u001b[39;49;00m)\n",
      "        }\n",
      "    preprocessing_combiner = tf.keras.layers.Concatenate(axis=-\u001b[34m1\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m#create a q_net\u001b[39;49;00m\n",
      "    q_net = q_network.QNetwork(\n",
      "        train_env.observation_spec(),\n",
      "        train_env.action_spec(),\n",
      "        preprocessing_layers=preprocessing_layers,\n",
      "        preprocessing_combiner=preprocessing_combiner,\n",
      "        fc_layer_params=fc_layer_params)\n",
      "\n",
      "    \u001b[37m#create optimizer\u001b[39;49;00m\n",
      "    optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
      "\n",
      "    \u001b[37m#create a global step coubter\u001b[39;49;00m\n",
      "    \u001b[37m#train_step_counter = tf.Variable(0)\u001b[39;49;00m\n",
      "    global_step = tf.compat.v1.train.get_or_create_global_step()\n",
      "\n",
      "    \u001b[37m#create agent\u001b[39;49;00m\n",
      "    agent = dqn_agent.DqnAgent(\n",
      "        train_env.time_step_spec(),\n",
      "        train_env.action_spec(),\n",
      "        q_network=q_net,\n",
      "        optimizer=optimizer,\n",
      "        td_errors_loss_fn=common.element_wise_squared_loss,\n",
      "        \u001b[37m#train_step_counter=train_step_counter)\u001b[39;49;00m\n",
      "        train_step_counter=global_step)\n",
      "\n",
      "    agent.initialize()\n",
      "\n",
      "    \u001b[37m# (Optional) Optimize by wrapping some of the code in a graph using TF function.\u001b[39;49;00m\n",
      "    agent.train = common.function(agent.train)\n",
      "\n",
      "    magent = learningHelper(train_env=train_env, test_env=eval_env, agent=agent, global_step=global_step, collect_episodes = \u001b[34m10000\u001b[39;49;00m,\n",
      "    eval_interval=\u001b[34m5\u001b[39;49;00m, verbose=\u001b[34m0\u001b[39;49;00m, batch_size=\u001b[34m64\u001b[39;49;00m, chkpdir=\u001b[33m'\u001b[39;49;00m\u001b[33m./fc_chkp/\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    magent.restore_check_point()\n",
      "\n",
      "    train(magent,\u001b[34m20\u001b[39;49;00m)\n",
      "\u001b[37m#     magent.train_agent(1)\u001b[39;49;00m\n",
      "  \n",
      "\n",
      "    \u001b[37m#magent.train_agent_with_avg_ret_condition(100, 10000, 100)\u001b[39;49;00m\n",
      "    magent.store_check_point()\n",
      "    magent.restore_check_point()\n",
      "    magent.save_policy()\n",
      "    \n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "    main()\n"
     ]
    }
   ],
   "source": [
    "! pygmentize docker/agent.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "account_id = boto3.client(\"sts\").get_caller_identity().get(\"Account\")\n",
    "ecr_repository = \"sagemaker-debugger-fxproject-1\"\n",
    "tag = \":latest\"\n",
    "\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "uri_suffix = \"amazonaws.com\"\n",
    "if region in [\"cn-north-1\", \"cn-northwest-1\"]:\n",
    "    uri_suffix = \"amazonaws.com.cn\"\n",
    "image_uri = f\"{account_id}.dkr.ecr.{region}.{uri_suffix}/{ecr_repository}{tag}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'708823838148.dkr.ecr.us-east-2.amazonaws.com/sagemaker-debugger-fxproject-1:latest'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: docker: not found\n",
      "\n",
      "An error occurred (RepositoryAlreadyExistsException) when calling the CreateRepository operation: The repository with name 'sagemaker-debugger-fxproject-1' already exists in the registry with id '708823838148'\n"
     ]
    }
   ],
   "source": [
    "!$(aws ecr get-login --region $region --registry-ids $account_id --no-include-email)\n",
    "!aws ecr create-repository --repository-name $ecr_repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'708823838148.dkr.ecr.us-east-2.amazonaws.com/sagemaker-debugger-fxproject:latest'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: sm-docker: not found\n"
     ]
    }
   ],
   "source": [
    "!sm-docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
